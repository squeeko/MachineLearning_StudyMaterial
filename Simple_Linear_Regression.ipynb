{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression is to predict the value of a CONTINUOUS response variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# X represents the features of our training data which in this case are the diameters\n",
    "# of the pizzas\n",
    "\n",
    "# A scikit-learn convention is to name the MATRIX of the feature vectors 'X'.\n",
    "\n",
    "# Uppercase letters indicate MATRICES and lowercase letter indicate VECTORS.\n",
    "\n",
    "X = np.array([[6], [8], [10], [14], [18]]).reshape(-1, 1) \n",
    "# reshapes a matrix (rows and cols) we are making this a \n",
    "y = [7, 9, 13, 17.5, 18] # A 'List' vector representing the prices of the pizzas\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Pizza price plotted against diameter')\n",
    "plt.xlabel('Diameter in inches')\n",
    "plt.ylabel('Price in dollars')\n",
    "plt.plot(X, y, 'k.') # plt.plot(X, y, fmt = '[marker][line][color]'\") \n",
    "# k = black and '.' = the dot marker)\n",
    "plt.axis([0, 25, 0, 25]) # axis scale -  xmin, xmax, ymin, ymax\n",
    "plt.grid(True) # show grid lines\n",
    "plt.show() # display the plot \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is a positive relationship as the prices increases with the increased diameter of the pizza. This relationship is modeled using Linear Regression - a continuous response variable. Below I will show how Linear Regression works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 12\" pizza should cost: $13.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression() # Create the instance of the estimator\n",
    "model.fit(X, y) # Fit the model on the training data\n",
    "\n",
    "# Predict the price of a pizza with a diameter that has never been seen before\n",
    "test_pizza = np.array([[12]])\n",
    "predicted_price = model.predict(test_pizza) [0]\n",
    "print('A 12\" pizza should cost: $%.2f' % predicted_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression assumes that a linear relationship exists between the RESPONSE variable and the EXPLANATORY variable. A linear surface called a HYPERPLANE is used to model this relationship. A HYPERPLANE is a subspace that has one dimension less than the ambient space that contains it. In simple linear regression there are TWO DIMENSIONS, one each for the EXPLANATORY and the RESPONSE variables. A REGRESSION HYPERPLANE has ONE DIMENSION which is a LINE. \n",
    "\n",
    "## From Wiki - In geometry, a hyperplane is a subspace whose dimension is one less than that of its ambient space. If a space is 3-dimensional then its hyperplanes are the 2-dimensional planes, while if the space is 2-dimensional, its hyperplanes are the 1-dimensional lines. ... By its nature, it separates the space into two half spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LinearRegression class is an ESTIMATOR which PREDICTS A VALUE based on observed data. In scikit-learn ALL ESTIMATORS implement the 'FIT' and 'PREDICT' methods. The 'FIT' method is used to LEARN THE PARAMETERS of a model and the 'PREDICT' method is used to PREDICT THE VALUE OF A RESPONSE VARIABLE FOR A EXPLANATORY VARIABLE using the LEARNED PARAMETERS. \n",
    "\n",
    "## Estimators by category and usage\n",
    "\n",
    "## https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "## y = a + Bx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATING THE FITNESS of a MODEL using the COST FUNCTION ALSO KNOWN AS THE LOSS FUNCTION. The differences in the MODEL between the predicted and observed values are called RESIDUALS or TRAINING ERRORS. \n",
    "\n",
    "## The differences in the TEST DATA between the predicted and observed values are called PREDICTION or TEST ERRORS. This is shown by the vertical lines between the regression hyperplane (line) and the points of the training instances.\n",
    "\n",
    "## I will use the RSS (Residual Sum of Squares) to measure the model's fitness. This is done by SUMMING THE SQUARE RESIDUALS for all of the training examples.\n",
    "\n",
    "## https://en.wikipedia.org/wiki/Residual_sum_of_squares\n",
    "\n",
    "## SSres = sum of 'n'(yi - f(xi))**2\n",
    "\n",
    "## 'n' is the number of observed values, 'yi' is the OBSERVED VALUE and 'f(x)' is the PREDICTED VALUE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 1.75\n"
     ]
    }
   ],
   "source": [
    "# Computing the RSS for the model \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression() # Create the instance of the estimator\n",
    "model.fit(X, y) # Fit the model on the training data\n",
    "\n",
    "# Predict the price of a pizza with a diameter that has never been seen before\n",
    "test_pizza = np.array([[12]])\n",
    "predicted_price = model.predict(test_pizza) [0]\n",
    "# print('A 12\" pizza should cost: $%.2f' % predicted_price)\n",
    "print('Residual sum of squares: %.2f' % np.mean((model.predict(X) - y) ** 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS (Ordinary Least Squares) or LINEAR LEAST SQUARES\n",
    "\n",
    "## OLS uses the training data to learn the values of the parameters for SIMPLE LINEAR REGRESSION that produces the best fitting model. \n",
    "\n",
    "## Solving the OLS for Simple Linear Regression\n",
    "## The equation for simple linear regression is y = a + Bx and my goal is to solve for 'a' and 'b' and to minimize the cost function. To solve for 'B' first I have to calculate the VARIANCE of x and the COVARIANCE of 'x' and 'y'. Remember VARIANCE is how far apart a set of values are spread out. If all of the values in the set are equal then we have NO VARIANCE '0'. A SMALL VARIANCE indicates the values are NEAR THE MEAN of the set. Conversely, a LARGE VARIANCE indicates the values are FAR FROM THE MEAN AND EACH OTHER.\n",
    "\n",
    "## VARIANCE is calculated by the SQUARING the DIFFERENCE between EACH VALUE and the MEAN and DIVIDING that by the NUMBER OF INSTANCES MINUS 1. \n",
    "\n",
    "## var(x) = sum of all 'n' (xi - x_bar)**2/n-1\n",
    "\n",
    "## x_bar is the mean of x and xi is the value of x for ith training instance and n is the number of training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  11.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[6], [8], [10], [14], [18]]).reshape(-1, 1)\n",
    "x_bar = X.mean()\n",
    "print('Mean: ', x_bar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance:  23.2\n"
     ]
    }
   ],
   "source": [
    "# Note that I subtract one from the number of trraining instances when \n",
    "# calculating the sample variance.\n",
    "# This technique is called Bessel's correction. It corrects the bias in the estimation \n",
    "# of the population variance from a sample.\n",
    "\n",
    "variance = ((X - x_bar)**2).sum() / (X.shape[0] - 1)\n",
    "print('Variance: ', variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance is a measure of how much two variables change together. If they INCREASE  TOGETHER their COVARIANCE IS POSITIVE, if one INCREASES while the other DECREASES, their COVARIANCE IS NEGATIVE. If they have no effect on each other, their COVARIANCE IS ZERO.\n",
    "\n",
    "## covar(x,y) = (xi - x_bar)(yi - y_bar)/n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance:  22.65\n"
     ]
    }
   ],
   "source": [
    "# I will calculate the covariance\n",
    "# I used a list before to represent y but I will now use a numpy array which has a method to calculate the mean.\n",
    "# This is a List - 'y = [7, 9, 13, 17.5, 18]'\n",
    "# the following is an numpy array. Note the difference\n",
    "y = np.array([7, 9, 13, 17.5, 18])\n",
    "y_bar = y.mean()\n",
    "\n",
    "# I will transpose 'X' because both operands need to be 'row' vectors. \n",
    "# See what 'X' originally was\n",
    "# print(X - x_bar)\n",
    "# [[-5.2]\n",
    "# [-3.2]\n",
    "# [-1.2]\n",
    "# [ 2.8]\n",
    "# [ 6.8]] \n",
    "X_cov = np.transpose(X - x_bar)\n",
    "covariance = np.multiply(X_cov, y - y_bar).sum() / (X.shape[0] - 1)\n",
    "print('Covariance: ', covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that I have calculated the VARIANCE of the EXPLANATORY VARIABLES and the COVARIANCE of the RESPONSE and EXPLANATORY VARIABLES, I can solve for 'b' which is the following formula:\n",
    "## cov(x,y) / var(x), 22.65 / 23.2 = 0.98 roughly\n",
    "\n",
    "## Now we can solve for 'a', 'y_bar' is the mean of 'y'\n",
    "## a = y_bar - Bx\n",
    "## Here 'y_bar' is the mean of 'y' and  'x_bar' is the mean of 'x'.\n",
    "## 'x_bar' and 'y_bar' are the COORDINATES of the CENTROID, a POINT THAT THE MODEL MUST PASS THROUGH.\n",
    "\n",
    "## a = 12.9 - 0.98 * 11.2 = 1.97 roughly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "## I have used a learning algorithm (ESTIMATOR) to estimate a model's parameters from the TRAINING DATA. How can I assess whether the model is a good representation of the real relationship? I will now add a fourth columns which contains the prices predicted by the model. \n",
    "\n",
    "## I can evaluate my model's predictive capacity using a measure called 'R-SQUARED' also known as the 'COEFFICIENT OF DETERMINATION'. In the case of SIMPLE LINEAR REGRESSION, 'R-SQUARED' is equal to the square of the 'PEARSON PRODUCT-MOMENT CORRELATION COEFFICIENT' (PPMCC) or 'PEARSON'S R'. 'R-SQUARED' must be a positive number from '0' to '1', if 'R-SQUARED' describes the proportion of variance in the RESPONSE VARIABLE that is explained by the model, it cannot be greater than '1' or less than '0'. Other methods do not calculate 'R-SQUARED' as the square of 'PEARSON'S R'. 'R-SQUARED' can be negative if the model performs poorly and is sensitive to outliers and can increase as features are added to the model. \n",
    "\n",
    "## Using the method used by scikit-learn to calculate 'R-SQUARED'. \n",
    "## First I must measure the 'SUM OF SQUARES'. 'yi' is the 'OBSERVED VALUE' of the 'RESPONSE VALUE' for the 'ith' 'TEST INSTANCE' and 'y_bar' is the MEAN OF THE OBSERVED VALUES OF THE RESPONSE VARIABLES.\n",
    "\n",
    "## SStot = sum of all 'n'(yi - y_bar)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next I must find the RSS\n",
    "## SSres = sum of 'n'(yi - f(xi))**2  \n",
    "## 'n' is the number of observed values, 'yi' is the OBSERVED VALUE and 'f(x)' is the PREDICTED VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally I find R-SQUARED using the following\n",
    "\n",
    "## R**2 = 1 - SSres / SStot\n",
    "## In this instance it would be 1 - 19.20 / 56.8 = 0.66 roughly\n",
    "## The 'SCORE' method of 'LinearRegression' returns the model's 'R-SQUARED' value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the r_squared value of the model: 0.66\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train = np.array([6, 8, 10, 14, 18]).reshape(-1, 1)\n",
    "y_train = [7, 9, 13, 17.5, 18]\n",
    "\n",
    "X_test = np.array([8, 9, 11, 16,12]).reshape(-1, 1)\n",
    "y_test = [11, 8.5, 15, 18, 11]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "r_squared = model.score(X_test, y_test)\n",
    "print('This is the r_squared value of the model: %.2f' %r_squared)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
